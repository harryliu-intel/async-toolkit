\documentclass{article}
\usepackage{graphicx}
\usepackage{epsf}

\usepackage{floatflt}
\usepackage{fancyhdr}
\usepackage{array}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{sectsty}
\usepackage{breqn}
%\allsectionsfont{\mdseries\sffamily}
\allsectionsfont{\mdseries\sc}

\usepackage{caption}
\captionsetup{margin=2pc,font=small,labelfont=bf}

\usepackage{tikz}
\def\checkmark{\tikz\fill[scale=0.15](0,.35) -- (.25,0) -- (1,.7) -- (.25,.15) -- cycle;}
\def\check#1{\overset{\checkmark}{#1}}

%%%%%%%%%%%%%%Mika's figure macro%%%%%%%%%%%%%%%%%%%%%%%%%%%
\def\listcaption_ins_epsfig#1#2#3#4{
  \begin{figure}[!tbph!]
  \bigskip
  \begin{center}
  \includegraphics[width=#1]{#2}
  \end{center}
  \caption[#4]{#3}\label{fig:#2}
  \bigskip
  \end{figure}
}

\def\insepsfig#1#2#3{
  \begin{figure}[!tbph!]
  \bigskip
  \begin{center}
  \includegraphics[width=#1]{#2}
  \end{center}
  \caption{#3}\label{fig:#2}
  \bigskip
  \end{figure}
}

\def\rotins_epsfig_listcaption#1#2#3#4#5{
  \begin{figure}[!tbph!]
  \bigskip
  \begin{center}
  \includegraphics[angle=#4,width=#1]{#2}
  \end{center}
  \caption[#5]{#3}\label{fig:#2}
  \bigskip
  \end{figure}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\oddsidemargin=0.15in
\evensidemargin=0.15in
\topmargin=0.2in
\textwidth=6.2truein


\pagestyle{plain}
%\lhead{\scriptsize\bfseries\sffamily DRAFT---INTEL CONFIDENTIAL---DRAFT}
%\chead{}\rhead{\thepage}
%\lfoot{}\cfoot{}\rfoot{}
%\renewcommand{\headrulewidth}{0pt}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\input{build/hash}

\title{Pre-Silicon Yield Modeling \\ Under \\ Non-Independent Yield Models}
%\author{Mika Nystr\"om \\ {\tt mika.nystroem@intel.com}}

%\date{\today}

\begin{document}

\maketitle
\parindent=0pt
\parskip=1.5ex

\arraycolsep=1.4pt\def\arraystretch{1.5}

\section{Introduction}

Ever since the first IC was manufactured, manufacturing yield has been
one of the main limiters to progress in technology.  One way we
improve system yield is by adding hardware redundancy: if our design
requires $N$ subsystems to be operational, we manufacture $N+1$ on the
die and provide a scheme whereby a defective subsystem can be switched
out.

The standard pre-silicon method of modeling yield improvement under
redundancy is to employ the binomial formula, that is,
\begin{equation}\label{eq:basic}
  P(\text{at least $M$ out of $N$ subsystems OK}) = \sum_{k=M}^N {N \choose k}Y(1)^{k}(1-Y(1))^{N-k}
\end{equation}
where the yield of a single subsystem is given as $Y(1)$.  This method
is only correct under statistical independence of the individual
yields $Y(1)$.  Large inaccuracies are possible when defects are not
independent, for example when using Stapper's yield formula
\begin{equation}\label{eq:stapperyield}
  Y(A) = \left(1 + { AD_0 \over \alpha } \right)^{-n \alpha}
\end{equation}
with small $\alpha$.  We will use Stapper's formula in this paper, noting that the other popular yield formulas, namely Poisson's
formula and the Bose-Einstein distribution, are special cases of
Stapper's formula, with $\alpha \rightarrow +\infty$ for Poisson and
$\alpha = 1$ for Bose-Einstein.  The binomial formula (\ref{eq:basic})
is {\em only\/} correct for Poisson distributions.
For
very small values of Stapper's $\alpha$, and in particular for large chips,
we will see that the binomial formula  (\ref{eq:basic}) dramatically
over-estimates the benefit of adding redundancy to a chip design.

\section{Historical background}
  
It was realized early on that the Poisson process was not adequate for
describing the yield of ICs, and Murphy introduced a more
sophisticated method in (\ref{eq:murphy}) already in 1964.  Big
advances in yield modeling came from Moore's publication of Intel
yield data in the open literature in 1970~\cite{moore1970}.  Stapper in
particular refined Murphy's approach and applied P\'olya-Eggenberger
statistics (\ref{eq:stapperyield}) to the yield problem starting in
1973, rediscovering the yield formula (\ref{eq:stapperyield}) that
P\'olya and Eggenberger had developed in 1923 for a problem in botany.
Whereas the Poisson formulation implies that there is an underlying
constant rate of defects, the Stapper model allows for a highly
variable defect rate, to account for clustering.  In modern processes,
the variance of the defect density is modeled as being up to 50 times
its average value.

The resulting situation is something of a conundrum: redundancy
modeling uses the binomial formula, which assumes that subsystem
yields are independent; process yield modeling uses Stapper's model,
or something similar, which assumes that yields are clustered.  As we
shall see, large disagreements are possible in the computed yields of
redundantly provisioned systems.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Method}
We define {\em process yield\/} $Y$ as the probability that a
manufactured circuit is found to contain no manufacturing defects that
are fatal to its functioning according to its circuit specification.
Holding all else equal, process yield falls with circuit area.

We define {\em manufacturing yield\/} as the probability that a manufactured
circuit is found to contain no manufacturing defects that are fatal
its functioning according to its customer-visible specification.
Manufacturing yield can be different from, and then always higher than,
process yield, because only circuits that were inessential to the correct
customer-visible functioning of the system are faulty.  We call such circuits
{\em redundant.}

Let process yield $Y$ map from area $A$ in square
length units to a probability $Y(A)$ so that

\begin{equation} Y(A) \in [ 0 .. 1 ] \quad . \end{equation}

$Y(A)$ is decreasing in $A$.

Let it be given that a system $S$ comprises $N$ subsystems
$u_i$, each with area $A_{u_i}$, so that
\begin{equation}
  A_S = \sum A_{u_i} \quad .
\end{equation}
We call the set of subsystems
\begin{equation}
  \Sigma = \{ u_0, u_1, \ldots , u_{N-1} \} \quad . 
\end{equation}



We call the
probability that at least $M \leq N$ units are fabricated
correctly the {\em system manufacturing yield,} or for short, the {\em system yield:}
\begin{equation}
  P_{S(N)}(x \geq M) \quad . \label{eq:sysyield}
\end{equation}
We drop the subscript $S(N)$ when the meaning is clear from context.  

We consider the case that {\em exactly\/} $k$ out of $N$ subsystems
are functional, and we will write this analogously to
(\ref{eq:sysyield}) as $P_{S(N)}(x = k)$.

\section{General formulation}\label{sec:general}

We have
\begin{equation}
  P_{S(N)}(x \geq N) = P_{S(N)}(x = N) = Y\left(\sum_i A_{u_i}\right) = Y(A_S) \quad ,
\end{equation}
since this is the system yield of $S$ under the requirement that all
$N$ subsystems are fully functional, which is simply the process yield
of the area of the system $S$ or equivalently the $N$ subsystems $u_i$.

Let's consider the state of affairs after fabricating $S$.  Some number of
subsystems $u_i \in \Sigma$ will have been fabricated correctly, with the balance defective.  Let's define $C$ to be the set of correctly fabricated subsystems.  It is clear that
\begin{equation}
  C \subseteq \Sigma .
\end{equation}

If we now consider the power set of the set of subsystems, that is,
\begin{equation}
  2^\Sigma = \{ \emptyset, \{ u_0 \}, \{ u_1 \}, \ldots , \Sigma \}
\end{equation}
it is clear that each of the members  $\sigma \in 2^\Sigma$ corresponds to a certain physical area, namely
\begin{equation}
  A_\sigma = \sum_{u_i \in \sigma} A_{u_i} \quad ,
\end{equation}
and also that the result of fabrication will be that $C$ equals precisely one of the members of $2^\Sigma$.

We introduce the shorthand
\begin{equation}
  \pi_\tau = P(C = \tau)
\end{equation}
where we may write the subscript of $\pi$ as a bit vector $v$ where
bit $i$ in $v$ corresponds to whether $u_i \in \tau$.  By analogy with
boolean algebra, we call the individual, mutually exclusive $\pi_i$ the
{\em minterms\/} of the fabrication process.

The probability that the circuitry in $\sigma$ is fabricated correctly is
\begin{equation}
  P(\sigma \subseteq C) = Y(A_\sigma) = Y \left( \sum_{u_i \in \sigma} A_{u_i} \right) \quad , \label{eq:system}
\end{equation}
irrespective of whether the remaining blocks $u_i \not\in \sigma$ are
fabricated correctly or not. (We are considering the process yield of
only the subsystems selected by the subset $\sigma \subseteq \Sigma$.)
But this is exactly the same as the probability of the manufacturing
process's producing any $C$ that includes $\sigma$.
Therefore we may write
\begin{equation}
  \sum_{\tau \supseteq \sigma} P(C = \tau) = P(\sigma \subseteq C) \quad . \label{eq:master}
\end{equation}
We can compute the probability of arriving
 at  $\sigma \subseteq \Sigma$, for example, for the subsets
\begin{equation}
  \sigma : \sigma \subseteq \Sigma : || \sigma || \geq M \label{eq:countsets}
\end{equation}
corresponding to the probability $P_{S(N)}(x \geq M)$, i.e., the
desired value of the system yield from (\ref{eq:sysyield}).  The probability of any event $E$ that we care
to describe in terms of a constraint on $\sigma$ becomes
\begin{equation}
  P(E) = P\left( \bigcup_{\sigma_i \in E} \sigma_i \right) =
  P\left( \bigcup_{\sigma_i \in E} \left(\bigcup_{\tau_j: \sigma_i \subseteq \tau_j, \tau_j \in 2^\Sigma} \tau_j \right) \right) =
  \sum_{\tau_j} P(C = \tau_i) \quad . \label{eq:generalconstraint}
\end{equation}


\section{Restriction to equal subsystems}\label{sec:restricted}
Given that $S$ consists of $N$ {\em equal\/} subsystems and requires
at least $M \leq N$ of these to be functional in order for the system
to be functional, what is the system yield given the process yield and
the subsystem areas? We may write
  \begin{equation}
    \forall \tau : w(\tau) = n : \pi_\tau = \Pi_n \quad ,
  \end{equation}
  where $w(k)$ is the bit-sum function.
Now instead of a number of $\pi_\tau$, we have the probability
  $\Pi_n$, which pertains to any minterm with exactly $n$
  non-defective components. We can write
  \begin{equation}
    \Pi_N = \pi_{11\ldots1} = Y(NA_u) = Y(A_S)
  \end{equation}
  where now we write $A_u$ to signify that all the $A_{u_i}$ are the same, since all the $u_i$ are the same.
  We continue with 
  \begin{equation}
    \Pi_{N-1} = \pi_{1\ldots10} = \pi_{1\ldots01} = \cdots = \pi_{01\ldots11} 
  \end{equation}
  whose value is given by (\ref{eq:master}) as
\begin{equation}
\pi_{1\ldots10} + \pi_{11\ldots1} = \pi_{1\ldots01} + \pi_{11\ldots1} = \cdots = \pi_{01\ldots11} + \pi_{11\ldots1} = Y(N-1) \quad ,
\end{equation}
but we can simply write that as
\begin{equation}
  \Pi_{N-1} + \Pi_{N} = Y(N-1)
\end{equation}
and drop the $\pi_\tau$ from further consideration.  Now we may reduce (\ref{eq:system}) to the following recurrence:
\begin{equation}\begin{aligned}
    \Pi_N     &=& Y(N A_u) \\
    \Pi_{k-1}  &=& Y((k-1) A_u) - \left( \sum_{j=k}^{N} {N-k+1 \choose N-j} \Pi_j \right) \quad .
    \label{eq:recurrence}
\end{aligned}\end{equation}
This can be summarized as
\begin{equation}\label{eq:pi-summary}
  \Pi_{N-k} = \sum_{j=0}^k {k \choose j} (-1)^j Y((N-j)A_u) \quad .
\end{equation}
And now
\begin{equation}\begin{aligned}\label{eq:double-sum}
    P_{S(N)}(x \geq M) &=& \sum_{i=M}^{i=N} {N \choose i} \Pi_{i} \hskip 2ex& \hfill \\
                     &=& \sum_{i=0}^{N-M} {N \choose i}  \sum_{j=0}^{j=i}& {j \choose i} (-1)^j Y((N-j)A_u) \quad.
\end{aligned}\end{equation}


\subsection{Example}
\label{sec:ex16of17}
A system $S$ has been designed to operate with 16 identical subsystems
$u_0 \ldots u_{15} = u$.  Designers have added one spare unit
$u_{16}$, identical to all the others.  The area of each $u$ is 1. 

By (\ref{eq:recurrence}) we have the recurrence
\begin{equation}\begin{aligned}
    \Pi_{17}              &=& Y(17)& \\
    \Pi_{16}              &=& Y(16) - \Pi_{17} = Y(16)& - Y(17) \\
\end{aligned}\end{equation}
and, accordingly, the system yield
\begin{equation}\begin{aligned}
    P_{S(17)}(x \geq 16) &=& \Pi_{17} + {17 \choose 16} \Pi_{16} \\
                       &=& Y(17) + 17 (Y(16) - Y(17)) \\
                       &=& 17\, Y(16) - 16\, Y(17) \quad ,
\end{aligned}\end{equation}
which, as expected, equals the formulation under independence
\begin{equation}
  P_{i,16/17} = Y(1)^{17} + 17\, Y(1)^{16}(1 - Y(1))^1
\end{equation}
if and only if $Y \sim \hbox{Poisson}$ so that $Y(z) = Y(1)^z$.
This generalizes to
\begin{equation}
P_{S(N)}(x \geq N-1) = N \, Y((N-1)A) - (N-1)\, Y(NA) \quad .
\end{equation}

\section{Yield improvement}\label{sec:yield-improvement}
The {\em yield improvement\/} is the relative increase in the yield
from a certain design transformation.  For example, consider moving from a system of $N$ equal subsystems, all of which must work, to a system of $N+1$ equal subsystems, where still $N$ of which must work.  We can write the yield improvement
\begin{equation}
\begin{aligned}\label{eq:nplusoneimprovement}
  \upsilon_{N/N+1} & =  {Y_{N/N+1} - Y_{N/N} \over Y_{N/N}} \\
                 & = { (N+1) \, Y(N) - N\, Y(N+1) - Y(N) \over Y(N) } \\
                 & =  N { Y(N) - Y(N+1) \over Y(N) } \quad .
\end{aligned}
\end{equation}

\section{Integral formulation}
The main idea of the work of Murphy and Stapper is as follows.  If we assume
simple Poisson statistics, we can write
\begin{equation}
  Y(A) = e^{-AD_0}
\end{equation}
where $A$ is the area of the chip, and $D_0$ is the defect density of the process.  Murphy introduced the idea that $D$ itself is a random variable subject to some probability distribution (p.d.f.) $f(D)$, and then we may write
\begin{equation}\label{eq:murphy}
  Y(A) = \int_0^\infty e^{-AD} \, f(D) \, dD \quad ,
\end{equation}
From this equation, Stapper introduced
\begin{equation}
  f(D) = { 1 \over \Gamma(\alpha) \beta^\alpha } D^{\alpha - 1} e^{-D/\beta} \quad,
\end{equation}
whence he derived the yield formula~(\ref{eq:stapperyield}).  Now we take a step back and consider this an average process yield over a parameter
distribution $f(D)$: we are here writing that the process yield is of
the Poisson form $e^{-AD}$ but taken over an ensemble of yields
according to the p.d.f.~$f(D)$.  We may think of this, for example, as modeling a production
line that at any time produces defects according to the Poisson distribution $e^{-AD}$, but over time $D$ varies, drawn from the p.d.f.~$f(D)$.

If we restrict our process yields to Poisson yields $e^{-AD}$,
drawn from the ensemble $f(D)$.  The approach now is to compute the system
yield under Poisson assumptions (binomial distribution) and compute the
expected value of that system yield given the distribution of $D$.
We write the Poisson system yield $\Pi(D)$ and compute the expected
system yield across the process ensemble,
\begin{equation}\label{eq:ensemble-yield}
  <Y_S> = \int_0^\infty \Pi(D) f(D) \, dD
\end{equation}
where each $\Pi(D)$ is straightforward to compute using the binomial formula.

In practice we evaluate
\begin{equation}
< Y_S > = \int_{-\infty}^{+\infty} \Pi(e^x) f(e^x) e^x\, dx \quad ,
\end{equation}
and we have implemented this approach in a software tool and verified that it vies the same answers as the polynomial formulation.

\subsection{Example}
We assume a generic deep-submicron process circa 2020
with $n=30$, $D_0 = 0.10$ (defects per square inch per layer), and $\alpha$ varying from 10 (close to a Poisson defect distribution) through 1 (Bose-Einstein) to 0.02 (a more reasonable value for a modern process). 

\insepsfig{4truein}{procs.eps}{Process defect distribution $f(e^x)$ for a variety of values of $\alpha$.}

In figure~\ref{fig:procs.eps} we see the expected distribution
$f(e^x)$ as used in this section, for values of $\alpha$ of 0.02,
0.05, 1, and 10.

Now let's model a design to be fabricated in this process.  Our example processor is a HAL9000 processor, which for yield purposes is modeled by the
following Lisp S-expression:
\begin{verbatim}
(hal9000 (hal9000-misc 50)
   (* hal1000-modules 9 9 
      (hal1000 (hal1000-misc 5)
               (* hal1000-slices 10 8 (hal1000-slice 10))))))
\end{verbatim}
HAL9000 is a machine consisting of 9 modules of type
HAL1000, each of which contains 10 10-mm$^2$ slices of which any 8 are
required for correct operation.  Each HAL9000 also contains 50~mm$^2$
of other logic, and each HAL1000 another 5~mm$^2$.  Running our tool
on this design results output a part of which is shown in
figure~\ref{fig:hal9000-output}.  We also see the effect of yield
improvement from the redundancy in the design.  Finally, we also see
the yield of the ``downbins'' HAL8000 and HAL7000, which allow 1 and 2
of the HAL1000 subprocessors to be faulty.  We see that the yield improvement from redundancy on a HAL9000 is from 27.97\% to 48.24\%, that is, a 72.48\% improvement in yielding parts.  By contrast, using Poisson statistics with the same defect densities would show yields of 13.25\% and 53.54\% for a yield improvement of 304\%.  In other words, Poisson statistics would over-estimate yield improvement in this case by about $4\times$. 

\insepsfig{4truein}{Hal9000Screenshot.png}{Output of yield calculator tool on HAL9000 example.}

The danger of relying on the binomial formula for yield-improvement
calculations is illustrated in
figure~\ref{fig:hal9000-yield-improvement.eps}.  Here we see the yield improvement for the HAL9000 processor as a function of Stapper's $\alpha$ graphed in two ways.  The upper curve shows the yield improvement holding $D_0$ fixed at 0.1; the lower curve shows the perhaps more believable situation that we do have a good estimate for the yield at a fixed area (here assuming the effective $D_0$ is 0.06 at an area of 500~mm$^2$) but do not know $\alpha$ very well, although we may suspect that modern fabrication processes have $\alpha$ in the range 0.02--0.10.  We see that the Poisson assumptions  ($\alpha \gg 1$) that are commonly made over-estimate the yield improvement by anywhere from 2--20$\times$.
\insepsfig{4truein}{hal9000-yield-improvement.eps}{Yield improvement as a function of $\alpha$.}

\section{Summary and conclusion}
We have seen how to derive a general formula for the system yield of a
redundant hardware system under weak assumptions on process yield.  We
have furthermore shown how to more efficiently compute the system
yield of a system consisting of identical subsystems, and we have
discussed how practitioners over the years have found that
semiconductor defects are more highly clustered than the yield models
have allowed for.  We find it likely that existing yield models
overestimate the efficiacy of adding hardware redundancy and thereby
mislead designers into considering redundancy in situations where it
may not be so effective.  Future work that remains to be done here is
to shown how to integrate results derived with our model into the
context of a larger system incorporating the system we are studing as
itself a subsystem (our equations as they stand are only applicable if
they can take the entire system of interest---probably a semiconductor
die---into consideration ``at once''), and doing so with computational
efficiency.

\section{Acknowledgements}

Karl
Papadantonakis suggested the numerical approach to Murphy's method and the
specific formulation used in section~\ref{sec:general}.  Helia Naeimi
continually critiqued the difficulty of some of the methods involved
and inspired many improvements.  Pat Bosshart provided Lisp models for
the yield of the next-generation Intel Barefoot switching chips.
Hayden Helm provided invaluable feedback on the statistical framework.
Kishore Maddi provided yield data and feedback on recently fabricated
products.  CherSian Chua took the time and effort to describe
the currently used yield models.  


\begin{thebibliography}{99}

\bibitem{scheme} W.~Clinger and J.~Rees, eds. {Revised$^4$ Report on the Algorithmic Language Scheme.}  In {\it ACM Lisp Pointers IV}, July--September 1991.

\bibitem{murphy} B.~T.~Murphy. Cost-size optima of monolithic integrated circuits. {\it Proc. IEEE}, 12({\bf 52}), pp.~1537--1545, Dec.~1964.

\bibitem{stapper1973}C.~H.~Stapper. Defect density distribution for LSI yield calculations. {\it IEEE Trans. on Electron Devices}, 7({\bf 20}), pp.~655--657, July 1973.

  \bibitem{stapper1980}C.~H.~Stapper. Yield Model for Productivity Optimization of VLSI Memory Chips with Redundancy and Partially Good Product.  {\it IBM J. Res. Develop.\/} 3({\bf 24}), May 1980.

\bibitem{moore1970}G.~E.~Moore. What level of LSI is best for you? {\bf Electronics} {\bf 43}, pp.~126--130, Feb.~1970.

\bibitem{polya1923}F.~Eggenberger and G.~P\'olya. \"Uber die Statistik verketteter Vorg\"ange. {\it Z. Angew. Math. Mech.}, ({\bf 3}), pp.~279--289, 1923.

\bibitem{numerical-recipes}{W.~H.~Press, B.~P.~Flannery, S.~A~Teukolsky, and W.~T.~Vetterling.  {\it Numerical Recipes in Fortran 77: The Art of Scientific Computing.}  Second edition.  Cambridge:\ Cambridge University Press, 1992.}

\bibitem{price}{J.~E.~Price. A new look at yield of integrated circuits, {\it Proc. IEEE}, 8({\bf 58}), pp.~1290â€“1291, August 1970.}

\end{thebibliography}

\end{document}




