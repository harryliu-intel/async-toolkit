\documentclass{article}
\usepackage{graphicx}
\usepackage{epsf}

\usepackage{floatflt}
\usepackage{fancyhdr}
\usepackage{array}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{sectsty}
\usepackage{breqn}
%\allsectionsfont{\mdseries\sffamily}
\allsectionsfont{\mdseries\sc}

\usepackage{caption}
\captionsetup{margin=2pc,font=small,labelfont=bf}

\usepackage{tikz}
\def\checkmark{\tikz\fill[scale=0.15](0,.35) -- (.25,0) -- (1,.7) -- (.25,.15) -- cycle;}
\def\check#1{\overset{\checkmark}{#1}}

%%%%%%%%%%%%%%Mika's figure macro%%%%%%%%%%%%%%%%%%%%%%%%%%%
\def\listcaption_ins_epsfig#1#2#3#4{
  \begin{figure}[!tbph!]
  \bigskip
  \begin{center}
  \includegraphics[width=#1]{#2}
  \end{center}
  \caption[#4]{#3}\label{fig:#2}
  \bigskip
  \end{figure}
}

\def\insepsfig#1#2#3{
  \begin{figure}[!tbph!]
  \bigskip
  \begin{center}
  \includegraphics[width=#1]{#2}
  \end{center}
  \caption{#3}\label{fig:#2}
  \bigskip
  \end{figure}
}

\def\rotins_epsfig_listcaption#1#2#3#4#5{
  \begin{figure}[!tbph!]
  \bigskip
  \begin{center}
  \includegraphics[angle=#4,width=#1]{#2}
  \end{center}
  \caption[#5]{#3}\label{fig:#2}
  \bigskip
  \end{figure}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\oddsidemargin=0.15in
\evensidemargin=0.15in
\topmargin=0.2in
\textwidth=6.2truein


\pagestyle{plain}
%\lhead{\scriptsize\bfseries\sffamily DRAFT---INTEL CONFIDENTIAL---DRAFT}
%\chead{}\rhead{\thepage}
%\lfoot{}\cfoot{}\rfoot{}
%\renewcommand{\headrulewidth}{0pt}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\input{build/hash}

\title{Pre-Silicon Yield Modeling \\ Under \\ Non-Independent Yield Models}
\author{Mika Nystr\"om \\ {\tt mika.nystroem@intel.com}}

\date{February 4, 2021}

\begin{document}

\maketitle
\parindent=0pt
\parskip=1.5ex

\arraycolsep=1.4pt\def\arraystretch{1.5}
\begin{abstract}
  A popular way of improving semiconductor chip yield is adding redundant
  hardware.  Analyzing the yield improvement of such
  redundancy is commonly done assuming that the yields of different
  components are independent of each other.  Meanwhile, process yield
  models have long since abandoned this assumption of independence.  This paper
  explains how to compute yield improvement
  under non-independent yield models and shows that large errors in
  estimating yield improvement are possible when assuming
  independence.
\end{abstract}

\section{Introduction}

{\em It never rains but it pours} --- British proverb

{\em When it rains, it pours} --- American advertising slogan

Ever since the first IC was manufactured, manufacturing yield has been
one of the main limiters to progress in technology.  One way we
improve system yield is by adding hardware redundancy: if our design
requires $N$ subsystems to be operational, we manufacture $N+1$ on the
die and provide a scheme whereby a defective subsystem can be swapped
out.

The standard pre-silicon method of modeling yield improvement under
redundancy is to employ the binomial formula, that is,
\begin{equation}\label{eq:basic}
  P(\text{at least $M$ out of $N$ subsystems OK}) = \sum_{k=M}^N {N \choose k}Y(1)^{k}(1-Y(1))^{N-k}
\end{equation}
where the yield of a single subsystem is given as $Y(1)$.  This method
is only correct under statistical independence of the individual
yields $Y(1)$.  Large inaccuracies are possible when defects are not
independent, for example when using Stapper's yield formula
\begin{equation}\label{eq:stapperyield}
  Y(A) = \left(1 + { AD_0 \over \alpha } \right)^{-n \alpha}
\end{equation}
with small $\alpha$\cite{stapper1973}.  We will use Stapper's formula
in this paper, noting that the other popular yield formulas, namely
Poisson's formula \cite{poisson} and the Bose-Einstein \cite{price} formula, are special cases of
Stapper's formula, with $\alpha \rightarrow +\infty$ for Poisson and
$\alpha = 1$ for Bose-Einstein.  The binomial formula (\ref{eq:basic})
is {\em only\/} correct for Poisson distributions.  For small values
of Stapper's $\alpha$, and in particular for large chips, we will see
that the binomial formula (\ref{eq:basic}) dramatically over-estimates
the benefit of adding redundancy to a chip design.

\section{Historical background}
  
It was realized early on that the Poisson process \cite{poisson,small} was not adequate for
describing the yield of ICs, and Murphy introduced a more
sophisticated method (\ref{eq:murphy}) already in 1964 \cite{murphy}.  Big advances
in yield modeling came from Moore's publication of Intel yield data in
the open literature in 1970~\cite{moore1970}.  Stapper in particular
used Moore's data to refine Murphy's approach by applying
gamma-distribution statistics to the yield problem in 1973 \cite{stapper1973},
rediscovering the yield formula (\ref{eq:stapperyield}) that P\'olya
and Eggenberger had developed in 1923 for a problem in botany \cite{polya1923}.
Whereas the Poisson formulation implies that there is an underlying
constant rate of defects, the Stapper model allows for a variable
defect rate, to account for defect clustering.

The resulting situation is something of a conundrum: redundancy
modeling uses the binomial formula, which assumes that subsystem
yields are independent; process yield modeling uses Stapper's model,
or something similar, which assumes that yields are dependent on
clustered defects and not independent.  The two formulations are
incompatible.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Method}
We define {\em process yield\/} $Y$ as the probability that a
manufactured circuit is found to contain no manufacturing defects that
are fatal to its functioning according to its circuit specification.

We define {\em manufacturing yield\/} as the probability that a manufactured
circuit is found to contain no manufacturing defects that are fatal
its functioning according to its customer-visible specification.
Manufacturing yield can be different from, and then always higher than,
process yield, because only circuits that were inessential to the correct
customer-visible functioning of the system are faulty.  We call such circuits
{\em redundant.}

Process yield $Y(A)$ maps from area $A$ in square
length units to a probability so that $Y(A) \in [ 0 .. 1 ]$ ;
$Y(A)$ is decreasing in $A$.

Let it be given that a system $S$ comprises $N$ subsystems
$u_i$, each with area $A_{u_i}$, so that
$ A_S = \sum A_{u_i}$ .
We call the set of subsystems
\begin{equation}
  \Sigma = \{ u_0, u_1, \ldots , u_{N-1} \} \quad . 
\end{equation}



We call the
probability that at least $M \leq N$ units are fabricated
correctly the {\em system manufacturing yield,} or for short, the {\em system yield:}
\begin{equation}
  P_{S(N)}(x \geq M) \quad . \label{eq:sysyield}
\end{equation}
We also consider the case that {\em exactly\/} $k$ out of $N$ subsystems
are functional, written $P_{S(N)}(x = k)$.

\section{General formulation}\label{sec:general}

We have
\begin{equation}
  P_{S(N)}(x \geq N) = P_{S(N)}(x = N) = Y\left(\sum_i A_{u_i}\right) = Y(A_S) \quad ,
\end{equation}
since this is the system yield of $S$ under the requirement that all
$N$ subsystems are fully functional, which is simply the process yield
of the area of the system $S$ or equivalently the $N$ subsystems $u_i$.

Let's consider the state of affairs after fabricating $S$.  Some number of
subsystems $u_i \in \Sigma$ will have been fabricated correctly, with the balance defective.  Let's define $C$, where $C \subseteq \Sigma$, to be the set of correctly fabricated subsystems. 

If we now consider the power set of the set of subsystems, that is,
\begin{equation}
  2^\Sigma = \{ \emptyset, \{ u_0 \}, \{ u_1 \}, \ldots , \Sigma \}
\end{equation}
each of the members  $\sigma \in 2^\Sigma$ corresponds to a certain physical area
\begin{equation}
  A_\sigma = \sum_{u_i \in \sigma} A_{u_i} \quad ,
\end{equation}
and also that the result of fabrication will be that $C$ equals precisely one of the members of $2^\Sigma$.

We introduce the shorthand $\pi_\tau = P(C = \tau)$
where we may write the subscript of $\pi$ as a bit vector $v$ where
bit $i$ in $v$ corresponds to whether $u_i \in \tau$.  By analogy with
boolean algebra, we call the individual, mutually exclusive $\pi_i$ the
{\em minterms\/} of the fabrication process.

The probability that the circuitry in $\sigma$ is fabricated correctly is given by the yield of their area
\begin{equation}
  P(\sigma \subseteq C) = Y(A_\sigma) = Y \left( \sum_{u_i \in \sigma} A_{u_i} \right) \quad , \label{eq:system}
\end{equation}
irrespective of whether the remaining blocks $u_i \not\in \sigma$ are
fabricated correctly or not. (We are considering the process yield of
only the subsystems selected by the subset $\sigma \subseteq \Sigma$.)
But this is exactly the same as the probability of the manufacturing
process's producing any $C$ that includes $\sigma$.
Therefore we may write
\begin{equation}
  \sum_{\tau \supseteq \sigma} P(C = \tau) = P(\sigma \subseteq C) \quad . \label{eq:master}
\end{equation}
We can compute the probability of arriving
 at  $\sigma \subseteq \Sigma$, for example, for the subsets
\begin{equation}
  \sigma : \sigma \subseteq \Sigma : || \sigma || \geq M \label{eq:countsets}
\end{equation}
corresponding to the probability $P_{S(N)}(x \geq M)$, i.e., the
desired value of the system yield from (\ref{eq:sysyield}).  The probability of any event $E$ that we care
to describe in terms of a constraint on $\sigma$ becomes
\begin{equation}
  P(E) = P\left( \bigcup_{\sigma_i \in E} \sigma_i \right) =
  P\left( \bigcup_{\sigma_i \in E} \left(\bigcup_{\tau_j: \sigma_i \subseteq \tau_j, \tau_j \in 2^\Sigma} \tau_j \right) \right) =
  \sum_{\tau_j} P(C = \tau_i) \quad . \label{eq:generalconstraint}
\end{equation}


\section{Restriction to equal subsystems}\label{sec:restricted}
Given that $S$ consists of $N$ {\em equal\/} subsystems and requires
at least $M \leq N$ of these to be functional in order for the system
to be functional, what is the system yield given the process yield and
the subsystem areas? We may write
  \begin{equation}
    \forall \tau : w(\tau) = n : \pi_\tau = \Pi_n \quad ,
  \end{equation}
  where $w(k)$ is the bit-sum function.
Now instead of a number of $\pi_\tau$, we have the probability
  $\Pi_n$, which pertains to any minterm with exactly $n$
  non-defective components. We can write
  \begin{equation}
    \Pi_N = \pi_{11\ldots1} = Y(NA_u) = Y(A_S)
  \end{equation}
  where now we write $A_u$ to signify that all the $A_{u_i}$ are the same, since all the $u_i$ are the same.
  We continue with 
  \begin{equation}
    \Pi_{N-1} = \pi_{1\ldots10} = \pi_{1\ldots101} = \cdots = \pi_{01\ldots11} 
  \end{equation}
  whose value is given by (\ref{eq:master}) as
\begin{equation}
\pi_{1\ldots10} + \pi_{11\ldots1} = \pi_{1\ldots101} + \pi_{11\ldots1} = \cdots = \pi_{01\ldots11} + \pi_{11\ldots1} = Y(N-1) \quad ,
\end{equation}
but we can simply write that as
\begin{equation}
  \Pi_{N-1} + \Pi_{N} = Y(N-1)
\end{equation}
and drop the $\pi_\tau$ from further consideration.  Now we may reduce (\ref{eq:system}) to the following recurrence:
\begin{equation}\begin{aligned}
    \Pi_N     =& Y(N A_u) \\
    \Pi_{k-1} =& Y((k-1) A_u) - \left( \sum_{j=k}^{N} {N-k+1 \choose N-j} \Pi_j \right) \quad .
    \label{eq:recurrence}
\end{aligned}\end{equation}
This can be summarized as
\begin{equation}\label{eq:pi-summary}
  \Pi_{N-k} = \sum_{j=0}^k {k \choose j} (-1)^j Y((N-j)A_u) \quad ,
\end{equation}
so that
\begin{equation}\begin{aligned}\label{eq:double-sum}
    P_{S(N)}(x \geq M) 
                     &=& \sum_{i=0}^{N-M} {N \choose i}  \sum_{j=0}^{j=i}& {i \choose j} (-1)^j Y((N-j)A_u) \quad.
\end{aligned}\end{equation}


\subsection{Example}
\label{sec:ex16of17}
A system $S$ has been designed to operate with 16 identical subsystems
$u_0 \ldots u_{15} = u$.  Designers have added one spare unit
$u_{16}$, identical to all the others.  The area of each $u$ is 1. 

By (\ref{eq:recurrence}) we have the recurrence
\begin{equation}\begin{aligned}
    \Pi_{17}              &=& Y(17)& \\
    \Pi_{16}              &=& Y(16) - \Pi_{17} = Y(16)& - Y(17) \\
\end{aligned}\end{equation}
and, accordingly, the system yield
\begin{equation}\begin{aligned}\label{eq:16of17}
    P_{S(17)}(x \geq 16) &= \Pi_{17} + {17 \choose 16} \Pi_{16} \\
                       &= Y(17) + 17 (Y(16) - Y(17)) \\
                       &= 17\, Y(16) - 16\, Y(17) \quad ,
\end{aligned}\end{equation}
which, as expected, equals the formulation under independence
\begin{equation}\label{eq:16of17-independent}
  P_{i,16/17} = Y(1)^{17} + 17\, Y(1)^{16}(1 - Y(1))^1
\end{equation}
if and only if $Y \sim \hbox{Poisson}$ so that $Y(z) = Y(1)^z$.
The result (\ref{eq:16of17}) generalizes to
\begin{equation}
P_{S(N)}(x \geq N-1) = N \, Y((N-1)A_u) - (N-1)\, Y(NA_u) \quad .
\end{equation}

The {\em yield improvement\/} is the relative increase in the yield
from a certain design transformation.  For example, consider moving from a system of $N$ equal subsystems of area 1, all of which must work, to a system of $N+1$ equal subsystems, where still $N$ must work.  The yield improvement
\begin{equation}
\begin{aligned}\label{eq:nplusoneimprovement}
  \upsilon_{N/N+1} & =  {Y_{N/N+1} - Y_{N/N} \over Y_{N/N}} \\
                 & = { (N+1) \, Y(N) - N\, Y(N+1) - Y(N) \over Y(N) } \\
                 & =  N { Y(N) - Y(N+1) \over Y(N) } \approx - N {Y'(N) \over Y(N)}\quad .
\end{aligned}
\end{equation}

\section{Integral formulation}
The main idea of the work of Murphy and Stapper is as follows.  If we assume
simple Poisson statistics, we can write $Y(A) = e^{-AD_0}$
where $A$ is the area of the chip, and $D_0$ is the defect density of the process.  Murphy introduced the idea that $D$ itself is a random variable subject to some probability distribution (p.d.f.) $f(D)$, so that
\begin{equation}\label{eq:murphy}
  Y(A) = \int_0^\infty e^{-AD} \, f(D) \, dD \quad .
\end{equation}
Stapper introduced $f(D)$ from the gamma
distribution with shape parameter $\alpha$ and scale parameter
$\beta$, whence he derived the yield formula~(\ref{eq:stapperyield}).
Now we take a step back and consider this an average process yield
over a parameter distribution $f(D)$: we are here writing that the
process yield is of the Poisson form $e^{-AD}$ but taken over an
ensemble of yields according to the p.d.f.~$f(D)$.  We may think of
this, for example, as modeling a production line that at any time
produces defects according to the Poisson distribution $e^{-AD}$, but
wafer-to-wafer $D$ varies, drawn from the p.d.f.~$f(D)$.

The approach now is to compute the system yield under Poisson
assumptions (\ref{eq:basic}) and figure its
expected value given the distribution of $D$.  We
write the Poisson yield $\Pi(D)$ and write
\begin{equation}\label{eq:ensemble-yield}
  < Y_S > = \int_0^\infty \Pi(D) f(D) \, dD
\end{equation}
where each $\Pi(D)$ is straightforward to compute using the binomial formula~(\ref{eq:basic}).

In practice we make a change of variables $D = e^x$ and evaluate
\begin{equation}
< Y_S > = \int_{-\infty}^{+\infty} \Pi(e^x) f(e^x) e^x\, dx \quad ;
\end{equation}
we have implemented this approach in a software tool and verified that
it gives the same answers as the general formulation described in
section~\ref{sec:general}.\footnote{We have also developed two more
  formulations that lead to the same results as the integration
  formulation described here.  First, we developed a generalized
  polynomial formulation derived from the insight that the yield
  formulas can be written as a linear combination of yield-function
  evaluations and that this combination must equal the binomial
  formulation under independence, which allows a straightforward
  algorithm to discover the correct yield function (see our eqs.~(\ref{eq:16of17}) and~(\ref{eq:16of17-independent}) above).  This method is
  suitable for solving small problems with pen-and-paper calculations
  but appears to scale poorly to larger problems.  We have also developed a
  finite-differences formulation that shows promise for allowing fast
  computation of the yield formulas using algebraic methods.  We do
  not have the space here to describe these approaches further.}

\subsection{Example}
A generic deep-submicron process circa 2020 has $n=30$ (layers), $D_0 = 0.10$
(defects per square inch per layer), $\alpha$ (gamma shape parameter) in the range 0.02--0.10.
Let's model this process but let $\alpha$ vary from 10 (close to a
Poisson defect distribution) through 1 (Bose-Einstein) to 0.02
(contemporary ``reasonable'' value).

\insepsfig{4truein}{proc_9000.eps}{Process defect distribution $f(e^x)$ for a variety of values of $\alpha$.  The dashed line is $e^x \Pi(e^x)$ from the HAL9000 example.}

In figure~\ref{fig:proc_9000.eps}, we see the expected (transformed)
distribution $f(e^x)$ as used in this section, for values of $\alpha$
of 0.02, 1, and 10.  As $\alpha \rightarrow +\infty$, the distribution
sharpens into a Dirac delta function, corresponding to a pure Poisson
defect process.  The yield is computed by multiplying the dashed curve
in the figure, representing $e^x \Pi(e^x)$ of a
specific hardware design, by the solid-line $f(D)$ corresponding to the
fabrication process, and integrating the result.

Now let's model a design to be fabricated in this process.  Our example is a ``HAL9000'' processor, which for yield purposes is modeled by the
following Lisp S-expression\cite{scheme}:
\begin{verbatim}
(hal9000 (hal9000-misc 50)
   (* hal1000-modules 9 9 
      (hal1000 (hal1000-misc 5)
               (* hal1000-slices 10 8 (hal1000-slice 10))))))
\end{verbatim}
This says that HAL9000 is a machine consisting of 9 modules of type
HAL1000, each of which contains 10 10-mm$^2$ slices of which any 8 are
required for correct operation.  Each HAL9000 also contains 50~mm$^2$
of other logic, and each HAL1000 another 5~mm$^2$.  Running our tool
on this design results in output a part of which is shown in
figure~\ref{fig:Hal9000Screenshot.png}.  The output shows the effect of yield
improvement from the redundancy in the design.  Finally, we also see
the yield of the ``downbins'' HAL8000 and HAL7000, which allow 1 and 2
of the HAL1000 subprocessors to be faulty, for less choosy customers.

\insepsfig{6truein}{Hal9000Screenshot.png}{Output of yield calculator tool on HAL9000 example.}

The danger of relying on the binomial formula for yield-improvement
calculations is illustrated in
figure~\ref{fig:hal9000-yield-improvement.eps}.  Here we see the yield
improvement for the (top-bin) HAL9000 processor as a function of Stapper's
$\alpha$ graphed in two ways.  The upper curve shows the yield
improvement holding $D_0$ fixed at 0.1; the lower curve shows the
perhaps more believable situation that we do have a good estimate for
the yield at a fixed area (here assuming the effective $D_0$ is 0.06
at an area of 500~mm$^2$) but do not know $\alpha$ very well, although
we may suspect that modern fabrication processes have $\alpha$ in the
range 0.02--0.10. Results of evaluating at two points are shown in table~\ref{tbl:yi}: we see that the Poisson assumption results in errors in the yield improvement lying roughly in the range 5--10$\times$.
\insepsfig{4truein}{hal9000-yield-improvement.eps}{Yield improvement
  as a function of $\alpha$.}
\begin{table}
  \begin{center}
  \begin{tabular}{| c || c | c | c || c | c | c || c |}
    \hline
     & \multicolumn{3}{c ||}{$\alpha\gg 1$}       &  \multicolumn{3}{c ||}{$\alpha = 0.02$} &  \\
    \hline
    Method       & Base & Improved & Yield       & Base & Improved & Yield & Error \\
           & yield      & yield    & imp. & yield      & yield    & imp. & factor         \\
    \hline
    Fixed $D_0$         & 2.2\% & 18.0\% & 694\%  &   30.3\% & 50.7\% & 67.5\% & 10.3$\times$ \\   
    Fixed yield & 10.8\% & 48.2\% & 345\% &   19.5\% & 34.1\% & 74.5\% &    4.63$\times$ \\
    \hline
  \end{tabular}
  \end{center}
  \caption{Yield improvement for HAL9000 design assuming $\alpha \gg 1$ vs.~$\alpha = 0.02$.}\label{tbl:yi}
\end{table}

\section{Summary and conclusion}
We have seen how to derive a general formula for the system yield of a
redundant hardware system under weak assumptions on process yield and
applied this to defect distributions that are more reasonable than
simple Poisson distributions.  We find it likely that existing yield
models overestimate the efficacy of adding hardware redundancy and
thereby mislead designers into considering redundancy in situations
where it may not be so effective.  The results of this work are
currently being used in architectural studies of next-generation
Intel Barefoot division products.

\section{Acknowledgements}

Karl
Papadantonakis suggested the numerical approach to Murphy's method and the
specific formulation used in section~\ref{sec:general}.  Helia Naeimi
continually critiqued the difficulty of some of the methods involved
and inspired many improvements.  Pat Bosshart provided Lisp models for
the yield of the next-generation Intel Barefoot switching chips.
Hayden Helm provided invaluable feedback on the statistical framework.
Kishore Maddi provided yield data and feedback on recently fabricated
products.  CherSian Chua took the time and effort to describe
the currently used yield models.  


\begin{thebibliography}{99}

\bibitem{scheme} W.~Clinger and J.~Rees, eds. {Revised$^4$ Report on the Algorithmic Language Scheme.}  In {\it ACM Lisp Pointers IV}, July--September 1991.

\bibitem{murphy} B.~T.~Murphy. Cost-size optima of monolithic integrated circuits. {\it Proc.~IEEE}, 12({\bf 52}), pp.~1537--1545, Dec.~1964.

\bibitem{stapper1973}C.~H.~Stapper. Defect density distribution for LSI yield calculations. {\it IEEE Trans.~Electron Devices}, 7({\bf 20}), pp.~655--657, July 1973.

  \bibitem{stapper1980}C.~H.~Stapper. Yield Model for Productivity Optimization of VLSI Memory Chips with Redundancy and Partially Good Product.  {\it IBM J.~Res.~Develop.\/} 3({\bf 24}), May 1980.

\bibitem{moore1970}G.~E.~Moore. What level of LSI is best for you? {\it Electronics} ({\bf 43}), pp.~126--130, Feb.~1970.

\bibitem{polya1923}F.~Eggenberger and G.~P\'olya. \"Uber die Statistik verketteter Vorg\"ange. {\it Z.~Angew.~Math.~Mech.}, ({\bf 3}), pp.~279--289, 1923.

\bibitem{numerical-recipes}{W.~H.~Press, B.~P.~Flannery, S.~A~Teukolsky, and W.~T.~Vetterling.  {\it Numerical Recipes in Fortran 77: The Art of Scientific Computing.}  Second edition.  Cambridge:\ Cambridge University Press, 1992.}

\bibitem{price}{J.~E.~Price. A new look at yield of integrated circuits, {\it Proc.~IEEE}, 8({\bf 58}), pp.~1290--1291, August 1970.}

\bibitem{poisson}{S.~D.~Poisson.  Recherches sur la probabilit\'e des jugements en mati\`ere criminelle et en mati\`ere civile; pr\'ec\'ed\'ees des R\`egles g\'en\'erales du calcul des probabilit\'es.  Paris:\ Bachelier, 1837.}

\bibitem{small}{L.~v.~Bortkiewicz.  {\it Das Gesetz der kleinen Zahlen.}  Leipzig:\ Teubner, 1898.}

\end{thebibliography}

\end{document}




